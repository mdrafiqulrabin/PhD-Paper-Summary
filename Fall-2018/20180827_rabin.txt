Title: DeepXplore: Automated Whitebox Testing of Deep Learning Systems

Authors: Kexin Pei, Yinzhi Cao, Junfeng Yang, Suman Jana

Published in: SOSP 2017	

-------------x-------------x-------------x-------------

1.	What is your take-away message from this paper?

This paper aims to provide a general overview of DeepXplore automated whitebox framework for testing DL systems to find erroneous corner case behaviors and retrain the corresponding DL systems with those erroneous inputs to improve accuracy.

2.	What is the motivation for this work (both people problem and technical problem), and its distillation into a research question? Why doesn’t the people problem have a trivial solution? What are the previous solutions and why are they inadequate?

•	What is the motivation for this work (both people problem and technical problem), and its distillation into a research question? 

DL systems often demonstrate unexpected or incorrect behaviors in corner cases. In safety and security critical settings, such incorrect behaviors can lead to disastrous consequences. Therefore, safety and security critical DL systems must be tested systematically for different corner cases to detect and fix undesired behaviors. This presents a new systems problem as automated and systematic testing of DL systems for all corner cases.

•	Why doesn’t the people problem have a trivial solution? 

Input space is huge to test DL system properly. Manually generated test inputs are inadequate for covering such a large space and will not touch all parts of the system. Generating test cases from all aspect is hard and doing such thing requires expert knowledge and a significant engineering effort.

•	What are the previous solutions and why are they inadequate?

-	Traditional approach for testing DL systems does not consider the internals of the target DL system and is not able to find different corner cases that induce erroneous behaviors.
-	Recent works on adversarial deep learning only cover a small part of DL system’s logic.
-	High neuron coverage alone may not induce many erroneous behaviors while just maximizing different behaviors might simply identify different manifestations of the same underlying root cause.

3.	What is the proposed solution (hypothesis, idea, design)? Why is it believed it will work? How does it represent an improvement? How is the solution achieved?

•	What is the proposed solution (hypothesis, idea, design)?

-	First, authors introduce neuron coverage for systematically measuring the parts of a DL system exercised by test inputs. 
-	Next, they leverage multiple DL systems with similar functionality as cross-referencing oracles to avoid manual checking. 
-	Finally, they demonstrate how finding inputs for DL systems that both trigger many differential behaviors and achieve high neuron coverage can be represented as a joint optimization problem and solved efficiently using gradient based search techniques.

•	Why is it believed it will work?

The test inputs generated by DeepXplore can find lots of erroneous corner case of DL systems and can also be used to retrain the corresponding DL model to improve the model’s accuracy.

•	How does it represent an improvement? 

-	Find thousands of incorrect corner cases. 
-	Check neuron coverage over code coverage.
-	Formulate and solve joint optimization problem: finding a large number of behavioral differences while maximizing neuron coverage.
-	Improve the retrained DL model’s accuracy by up to 3%.

•	How is the solution achieved?

-	Select test datasets and DNNs
-	Set domain-specific constraints
-	Design and implement DeepXplore:
•	Maximize differential behaviors
•	Maximize neuron coverage
•	Joint optimization
-	Evaluate DeepXplore’s performance using two metrics: 
•	Neuron coverage of the generated tests 
•	Execution time for generating difference-inducing inputs
-	Find out erroneous corner case test inputs
-	Improving DNNs with DeepXplore:
•	Augmenting training data to improve accuracy
•	Detecting training data pollution attack

4.	What is the author's evaluation of the solution? What logic, argument, evidence, artifacts (e.g., a proof-of-concept system), or experiments are presented in support of the idea?

-	Neuron coverage: Neuron coverage is a significantly better metric than code coverage for measuring DNN testing comprehensiveness. DeepXplore, on average, covers 34.4% and 33.2% more neurons than random testing and adversarial testing. Increasing neuron coverage, similar to code coverage, becomes increasingly harder for higher values but even small increases in neuron coverage can improve the test diversity significantly.
-	Activation of neurons for different classes of inputs: Inputs coming from the same class share more activated neurons than those coming from different classes. As inputs from different classes tend to get detected through matching of different DNN rules, our result also confirms that neuron coverage can effectively estimate the numbers of different rules activated during DNN testing.
-	Execution time and number of seed inputs: DeepXplore is very efficient in terms of finding difference-inducing inputs as well as increasing neuron coverage.
-	Different choices of hyper parameters: Finding the first difference-inducing input for a given seed tend to be significantly harder than increasing the number of difference inducing inputs.
-	Testing very similar models with DeepXplore: DeepXplore is very good at finding differences even between DNNs with minute variations. As the number of differences goes down, the number of iterations to find a difference-inducing input goes up, i.e., it gets increasingly harder to find difference inducing tests between DNNs with smaller differences.

5.	What is your analysis of the identified problem, idea and evaluation? Is this a good idea? What flaws do you perceive in the work? What are the most interesting or controversial ideas? For work that has practical implications, ask whether this will work, who would want it, what it will take to give it to them, and when might it become a reality? 

•	What is your analysis of the identified problem, idea and evaluation? Is this a good idea? 

It seems good to me on following perspectives:
-	White-box testing paradigm is able to find different corner cases than black-box testing approaches.
-	Automated testing paradigm is able to reduce labeling effort than manual testing paradigm.
-	High test coverage for neuron coverage over code coverage.
-	Maximize neuron coverage during the joint optimization process to generate diverse difference inducing inputs.
-	Ensure that the generated tests are valid as those satisfy the custom domain-specific constraints.

•	What flaws do you perceive in the work? What are the most interesting or controversial ideas? 

-	Differential testing requires at least two different DNNs with the same functionality. DeepXplore take longer time to find difference-inducing inputs if two DNNs only differ slightly than significantly from each other.
-	Differential testing can only detect an erroneous behavior if at least one DNN produces different results than others. If all the tested DNNs make the same mistake, it cannot generate the corresponding test case.

•	For work that has practical implications, ask whether this will work, who would want it, what it will take to give it to them, and when might it become a reality? 

TBD

6.	What are the paper's contributions (author's and your opinion)? Ideas, methods, software, experimental results, experimental techniques? 

-	Introduce neuron coverage as the first white-box testing metric for DL systems that can estimate the amount of DL logic explored by a set of test inputs.
-	Demonstrate that the problem of finding a large number of behavioral differences between similar DL systems while maximizing neuron coverage can be formulated as a joint optimization problem. 
-	Present a gradient-based algorithm for solving joint optimization problem efficiently.
-	Show that the tests generated by DeepXplore can also be used to retrain the corresponding DL systems to improve accuracy by up to 3%.

7.	What are future directions for this research (author's and yours, perhaps driven by shortcomings or other critiques)?

TBD

8.	What questions are you left with? What questions would you like to raise in an open discussion of the work (review interesting and controversial points, above)? What do you find difficult to understand? List as many as you can.

•	What questions are you left with? What questions would you like to raise in an open discussion of the work (review interesting and controversial points, above)? 

TBD

•	What do you find difficult to understand? List as many as you can.

-	TensorFlow 1.0.1 and Keras 2.0.3 DL frameworks.
-	Detecting training data pollution attack.

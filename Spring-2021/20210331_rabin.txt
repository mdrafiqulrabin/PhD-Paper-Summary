Topic: 
Testing Fairness of Machine Learning Algorithms

Summary:
In recent years, machine learning (ML) algorithms are excessively being applied for various decision-making systems. However, we barely know how data are being
used, is there any bias in data usage? Fairness testing can help to detect biases in ML algorithms. It aims to find whether an ML algorithm fairly learns training
data or is biased to some protected attributes (i.e., address or sex). For example, an ML system (such as hiring suggestion or loan approval) should not take any
crucial decisions just for changing the value of address or sex. Similarly, it should use all data in the training set equally regardless of the ordering of
instances and features in data. Hence, the study of fairness in ML algorithms is an active area of research. I find this topic very interesting because an ML system
cannot be trustworthy if it has been proven as bias. Even many non-technical persons are using ML algorithms despite having a lack of understanding about the
underline implementation of those algorithms. Therefore, testing the fairness of ML algorithms can draw researchers' attention to developing fair algorithms.

References:
Sharma, Arnab and Wehrheim, Heike. 2019. Testing Machine Learning Algorithms for Balanced Data Usage. 
In Proceedings of the 12th IEEE Conference on Software Testing, Validation and Verification (ICST 2019). 
https://doi.org/10.1109/ICST.2019.00022

Title: DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing

Authors: Xiao Liu, Xiaoting Li, Rupesh Prajapati, Dinghao Wu.

Published in: AAAI 2019.

Keywords: N/A.

-------------x-------------x-------------x-------------

[1] Problem:

Compilers are important programming tools to build software but it remains buggy.
Fuzz testing is used with new or mutated test cases to find new vulnerabilities in compilers.
The grammar-based fuzzing requires an input grammar that can be encoded as rules of grammar.
But the grammar specification is so many pages of detail that make the problem of automatically generating syntactically valid inputs for grammar-based fuzzing.
In this paper, the authors introduce a language based fuzzing tool called DeepFuzz to address this problem.
DeepFuzz automatically generates C programs based on a generative Sequence-to-Sequence model.
Authors use this new generated C programs to fuzz C compilers (GCC and Clang/LLVM).
The result provides evidence that DeepFuzz can benefit testing efficacy in regards to the pass rate, code coverage and bugs.

[2] Solution:

DEEPFUZZ works on two stages: Program Generation and Compiler Testing; first generates syntactically correct programs and then use this programs to improve the compiler testing efficacy.
On the first stage, authors train a character-level Sequence-to-Sequence model (generative recurrent neural network) with the original test suites of production compilers to learn the language patterns of the input data. They tune parameters to encode the language patterns for C programs into the model on the training stage and then generate new programs by leveraging different generation strategies and sampling methods.
On the second stage, authors log the compiling messages and the execution trace by feeding the generated C programs to the compilers in different optimization levels. They analyze the compiling messages and the execution trace in order to improve the code coverages and to detect the new bugs.

[3] Evaluation:

Authors use 10,000 well-formed C programs of the GCC test suites as taring data for Sequence-to-Sequence model and then use the new generated C programs to fuzz C compilers (for both GCC-5 and Clang-3). 
Authors use three metrics to measure the effectiveness of DEEPFUZZ: Pass rate, coverage and bug.
Use command line of gcc to determine the pass rate: the program is correct if no error is reported during gcc command. The result shows that NoSample as our sampling method and G1 as generation strategy provides better pass rate.
Use gcov by gcc to collect the coverage information: line coverage, function coverage, and branch coverage. The result shows that Sample as our sampling method and G2 as generation strategy provides better coverage.
Use different optimization levels and compilers to trigger bugs: crashes or code errors. The result shows that DEEPFUZZ generated 82.63% syntax valid C programs and found 8 new bugs addressed by developers.
Authors also compared DEEPFUZZ with Csmith based on the the coverage improvements by both augmenting the GCC and LLVM test suites with 10,000 generated programs. The result shows that DEEPFUZZ achieves better coverage improvement than Csmith.

Title: Learn&Fuzz: Machine Learning for Input Fuzzing

Authors: Patrice Godefroid, Hila Peleg, Rishabh Singh.

Published in: ASE 2017.

Keywords: Fuzzing, Deep Learning, Grammar-based Fuzzing, Grammar Learning.

-------------x-------------x-------------x-------------

[1] Problem:

The grammar-based fuzzing is an important types of fuzzing use today with complex structured input formats (Ex. Web Browser). But this is not fully automated as it requires a manually defined input grammar to generate new/modified test cases.
This paper first shows how to automate the generation of an input grammar using sample inputs and machine-learning techniques.
This paper also defines the learn&fuzz challenge: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs.
Authors present SampleFuzz algorithm for the learn&fuzz challenge and detail a case study on the PDF parser of Microsoftâ€™s new Edge browser for the PDF format. 
The result provides evidence that SampleFuzz has pass rate high enough to generate diverse well-formed objects to exercise error-handling code of target parser.

[2] Solution:

The main steps of Learn&Fuzz is to make a corpus of PDF objects, train char-rnn model to learn a generative model of PDF objects and generate new PDF objects by different sampling strategies. 

To implement the Learn&Fuzz, authors first merge multiple the PDF files to make a corpus of PDF objects and then extract multiple set of training input and output sequences correspond to the sequences of characters in the corpus. Then they use a recurrent neural network based character-level language model (char-rnn) to learn a generative model of PDF objects. Finally, use the learnt model to generate new PDF objects by sampling the distribution given a starting prefix (NoSample/Sample/SampleSpace).

[3] Evaluation:

Authors randomly select 1,000 PDF objects as baseline and also mark the smallest 3 PDF files as host1, host2, host3, and combine them as host123. Then they recombined the 1,000 baseline objects with those 3 hosts to obtain 3 sets of 1,000 new PDF files: baseline1, baseline2 and baseline3. 

Authors run those objects to the target PDF parser and compute the coverage information. The result shows that coverage varies across hosts but the recombined PDF file is larger than the host alone.

Authors train the RNN model with two generation modes: Sample and SampleSpace. The result shows that SampleSpace has a better pass rate than Sample, but Sample has a better overall coverage than SampleSpace. Perfect pass-rate (like SampleSpace) generates almost only well-formed objects but noisier learning algorithm (like Sample)can not but exercise error-handling code.

After combining the learning with random fuzzing, the result shows that the pass rate goes down while increasing coverage. In addition to coverage and pass rate, during a 5 days longer experiment with Sample+Random including 100,000 objects and 300,000 PDF files found a stack-overflow bug in the Edge PDF parser. This bug was later confirmed and fixed by the Microsoft Edge development team.

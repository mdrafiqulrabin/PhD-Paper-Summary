Title: Semantically Equivalent Adversarial Rules for Debugging NLP models

Authors: Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin

Published in: ACL 2018

Keywords: N/A

Link: https://aclweb.org/anthology/papers/P/P18/P18-1079/

-------------x-------------x-------------x-------------

[1] Problem:

NLP models are increasingly used to solve tasks like classification, sentiment analysis, and visual question answering.
Beyond the accuracy, one of the most critical issues is oversensitivity where models make different predictions for 
similar inputs. The complexity of these models makes it difficult to debug, detect and fix. Recent studies show some
adversarial examples for images but the study on text is not yet well focused. Therefore, in this paper, authors introduce
semantically equivalent adversaries (SEAs) for text inputs with semantics-preserving perturbations. Authors generalize the
semantically equivalent adversaries (SEAs) into semantically equivalent adversarial rules (SEARs). The experimental
evaluation of SEAs and SEARs on three state-of-the-art domains shows that these semantics-preserving adversarial examples
are significant in debugging ML models.

[2] Solution:

Authors introduce a greedy algorithm-based SEAR process to find the set of semantically equivalent rules which can be used
to detect issues in the model. They first generate Semantically Equivalent Adversaries(SEAs) and present Semantically
Equivalent Adversarial Rules (SEARs). Semantically Equivalent Adversaries(SEAs): (1) Generate a set of paraphrases from the
original sentence with the neural machine translation based paraphrasing model. (2) Select semantics-preserving paraphrases
based on semantic score. Semantically Equivalent Adversarial Rules (SEARs): (1) Search for an exact match of original and
replace by the adversary paraphrase. (2) Propose rule for every adversary generated by SEAs. The followings are the SEAR
process: (1) Generalize the SEARs into candidate rules. (2) Filter out the non-semantic rules. (3) Select the optimal 
rules-based on submodular optimization (semantic equivalence, high adversary count, and non-redundancy). (4) Judge by 
humans whether the remains rules are bugs or not.

[3] Evaluation:

Authors evaluate the SEAs and SEARs on three domains of state-of-the-art models for different tasks: AllenNLP-BiDaF model
for machine comprehension, Visual7W model for visual question answering and fastText model for sentiment analysis. Authors
were interested to investigate: (a) Can humans find good adversaries?, (b) Can experts find high-impact bugs? In order to
compare the effectiveness of SEAs and SEARS, authors first take a random of 100 correctly-predicted samples for each task
and then compare based on three conditions: (1) only human-generated adversaries, (2) only SEA generated adversaries, 
(3) HSEA: adversaries generated by SEA and picked by human experts. The result shows HSEA is more efficient than human
experts in finding good adversaries and the SEARs outperform human experts in finding the oversensitivity bugs. Authors
perform another experiment to reduce the number of oversensitivity bugs by retaining the models with SEAs. 

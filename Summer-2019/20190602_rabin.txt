
Title: COSET: A Benchmark for Evaluating Neural Program Embeddings

Authors: 	Ke Wang, Mihai Christodorescu

Published in: arXiv 2019.

Keywords: N/A

Link: https://arxiv.org/abs/1905.11445

-------------x-------------x-------------x-------------

[1] Problem:

Neural program embedding is useful to test a large system but challenging for being limited in scalability. The recent 
focus of research is on modeling program semantics instead of syntax, but there is no well-established metrics for
evaluation. The recent NLP studies include the techniques to discover the textual patterns from the source code, the
techniques to learn the syntactic program embedding from the Abstract Syntax Trees (AST), etc. For the program semantics 
requirements, the deep-learning studies include various improvements in terms of features in the source code, execution,
symbolic traces, graph representation, etc. But the key and main challenge is how to evaluate those approaches. To address 
this issue, in this paper, authors introduce COSET framework for standardizing the evaluation of neural program embeddings.
Authors conduct a pilot study with program dataset for classification task and transform dataset for debugging tool on four 
prominent models: TreeLSTM, GGNN, APNN, and DYPRO. 

[2] Solution:

Authors design the benchmark to include sample varieties in terms of syntax, style, algorithms, etc. The problem samples are from a diverse set of programmers solving the same problem and also by transforming those programs in terms of optimization and refactoring. 
The benchmark design of COSET includes the following components: (1) Collect Program Dataset: 84,165 programs solving one of ten coding problems by Java, C#, and Python. (2) Program Labels: Basic operations, running time, pre-post-condition, etc. (3) Program Transformations: Semantics-Preserving Transformations (CVP, DCE, LU, Hoisting for compiler optimization and VR, NCS, CFR, CSU for software refactoring), Semantics-Approximating Transformations, and Semantics-Changing Transformations.
The traget models: TreeLSTM, gated graph neural network (GGNN), ASTâ€“Path neural network (APNN), and DYPRO.
The main two usages of COSET is (1) classification task and (2) debugging tool. Authors apply two evaluations for COSET: (1) Authors first use the main dataset to evaluate the prediction in terms accuracy and F1 score, and (2) Apply program transformations on the main test set to generate a new test set for stability prediction.

[3] Evaluation:

Authors evaluate the (a) Prediction and (b) Stability of COSET by classification accuracy and F1 score. 
For (a), authors first train models (GGNN, APNN, TreeLSTM, and DYPRO) on COSET to predict the semantic label of a test program. The result shows that DYPRO model has the highest accuracy and TreeLSTM has the lowest accuracy (TreeLSTM<APNN<GGNN<DYPRO). Then authors also measure the scalability in terms of program size (bytes). The result shows that accuracy decreases with program size. The static models (APNN>TreeLSTM>GGNN) drops accuracy very quickly than the dynamic model (DYPRO). 
COSET can find various type of misclassification such that types, variable names, syntactic structure, API usages, error handling, buggy code, semantic property, and scalability. The analysis reveals that the static models are unstable against syntax change as it changes the structural pattern of codes and the DYPRO is susceptible to buggy programs as it changes the execution trace.
For (b), authors apply semantics-preserving transformations on the main dataset and generate a new test set to evaluate the stability of prior prediction. The result shows that models hold adequate prediction (change in less than 30%). DYPRO perfectly handles software refactoring (VR, NCS, CFR, CSU) and almost handles all compiler optimization (CVP, DCE, LU, Hoisting). On the other hand in static models (TreeLSTM>GGNN>APNN), TreeLSTM is the most stable and APNN is most sensitive to the transformations.
Finally, the authors find that DYPRO achieves the best performance in terms of prediction and stability than static models. 
